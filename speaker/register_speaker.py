import os
import io
import numpy as np
import torchaudio
import sounddevice as sd
from scipy.io.wavfile import write
from resemblyzer import VoiceEncoder, preprocess_wav
from pydub import AudioSegment
from dotenv import load_dotenv
import logging

load_dotenv()

# ì„¤ì •
SAMPLE_RATE = 16000
RECORD_SECONDS = 5  # ë…¹ìŒ ì‹œê°„ (ì´ˆ)
OUTPUT_DIR = "data/speakers_wav"
EMBEDDING_PATH = "data/reference_multi.npy"

os.makedirs(OUTPUT_DIR, exist_ok=True)

def register_speaker_from_waveform(speaker_name: str, waveform: np.ndarray, sample_rate: int = SAMPLE_RATE):
    """
    waveform(float32 np.ndarray)ì™€ speaker_nameì„ ë°›ì•„ ì„ë² ë”©ì„ ì €ì¥
    """
    encoder = VoiceEncoder()
    logging.info(f"í™”ì ë“±ë¡: {speaker_name} ({waveform.shape})")
    preprocessed = preprocess_wav(waveform, sample_rate)
    embedding = encoder.embed_utterance(preprocessed)

    # ê¸°ì¡´ ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸°
    if os.path.exists(EMBEDDING_PATH):
        embeddings = np.load(EMBEDDING_PATH, allow_pickle=True).item()
    else:
        embeddings = {}

    embeddings[speaker_name] = embedding
    np.save(EMBEDDING_PATH, embeddings)
    logging.info(f"ğŸ’¾ ì„ë² ë”© ì €ì¥ ì™„ë£Œ: '{speaker_name}' â†’ {EMBEDDING_PATH}")
    logging.info(f"[ì„ë² ë”© ë“±ë¡ í˜„í™©] í˜„ì¬ ë“±ë¡ëœ í™”ì: {list(embeddings.keys())}")
    return True, speaker_name

def webm_bytes_to_numpy_waveform(webm_bytes, sample_rate=16000):
    """
    webm bytesë¥¼ í™”ì ë“±ë¡/ì¸ì‹ìš© numpy waveform(float32, mono, sample_rate)ë¡œ ë³€í™˜
    """    
    # WebM â†’ PCM ë³€í™˜
    audio = AudioSegment.from_file(io.BytesIO(webm_bytes), format="webm")
    
    # mono + ì›í•˜ëŠ” sample_rate ë³€í™˜
    audio = audio.set_channels(1).set_frame_rate(sample_rate)

    # numpy waveform ë³€í™˜
    samples = np.array(audio.get_array_of_samples()).astype(np.float32) / (1 << 15)
    return samples


## í…ŒìŠ¤íŠ¸ìš©
def register_speaker(speaker_name: str):
    encoder = VoiceEncoder()
    
    wav_path = os.path.join(OUTPUT_DIR, f"{speaker_name}.wav")
    
    # ì˜¤ë””ì˜¤ ë¡œë“œ ë° ì „ì²˜ë¦¬
    audio = AudioSegment.from_wav(wav_path)
    samples = np.array(audio.get_array_of_samples()).astype(np.float32) / 32768.0
    if audio.channels == 2:
        samples = samples.reshape((-1, 2)).mean(axis=1)

    preprocessed = preprocess_wav(samples, SAMPLE_RATE)
    embedding = encoder.embed_utterance(preprocessed)

    # ê¸°ì¡´ ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸°
    if os.path.exists(EMBEDDING_PATH):
        embeddings = np.load(EMBEDDING_PATH, allow_pickle=True).item()
    else:
        embeddings = {}

    # ì €ì¥
    embeddings[speaker_name] = embedding
    np.save(EMBEDDING_PATH, embeddings)
    print(f"ğŸ’¾ ì„ë² ë”© ì €ì¥ ì™„ë£Œ: '{speaker_name}' â†’ {EMBEDDING_PATH}")
